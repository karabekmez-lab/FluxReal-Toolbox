{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "KtIK11Z0fdNZ"
      },
      "outputs": [],
      "source": [
        "#Run below to import dependicies\n",
        "import time\n",
        "import os\n",
        "import re\n",
        "import cobra\n",
        "from cobra.io import load_matlab_model, read_sbml_model, save_matlab_model, write_sbml_model\n",
        "from cobra.flux_analysis import flux_variability_analysis\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "import warnings\n",
        "import logging"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AmCtSExyL9G9"
      },
      "source": [
        "# **Part 1 : Setting File Path**\n",
        "\n",
        "Please download your data:\n",
        "\n",
        "1. In your expression file, the column with genes has variosu names: Gene symbols / Gene names / Probe_ids etc.\n",
        "    \n",
        "> Rename  the column as **Gene** to process. <br>\n",
        "File must include only Gene column with other columns shows expression value. Remove unnecessery columns such as ID_REF.\n",
        "\n",
        "2.   Ensure that the file name and path, including its extension, is entered correctly.\n",
        "\n",
        "3.   Execute the provided code cells one by one.\n",
        "\n",
        "Supported file formats  :\n",
        "    \n",
        "> For model : .xml .mat <br>\n",
        "> For expression data : .xlsx .csv\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GP1zOa62JkrN",
        "outputId": "529e6cb5-cfed-469e-8a48-4248eca71eeb"
      },
      "outputs": [],
      "source": [
        "# Provide paths for your files here.\n",
        "model_file_path = \"C:/Users/Ben/Desktop/GPRmapper/Toolbox/Eflux_data/Case_study/yeast-GEM.mat\" \n",
        "expression_file_path  = \"C:/Users/Ben/Desktop/GPRmapper/Toolbox/Eflux_data/Case_study/normalized.xlsx\"\n",
        "\n",
        "\n",
        "# This code checks if your file paths are correct.\n",
        "if model_file_path:\n",
        "    print(f'Model file exists : \"{model_file_path}\".')\n",
        "else:\n",
        "    print(f'Model file does not exists or does not correct.')\n",
        "\n",
        "if expression_file_path:\n",
        "    print(f'Model file exists : \"{expression_file_path}\".')\n",
        "else:\n",
        "    print(f'Model file does not exists or does not correct.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7MnfwV3WL1r6"
      },
      "source": [
        "# **Part 2: Processing Model and Expression Data**\n",
        "\n",
        "To ensure smooth data processing, please follow these steps:\n",
        "\n",
        "*   Execute the provided code cells sequentially. This approach allows you to monitor the data processing progress effectively.\n",
        "\n",
        "*   Alternatively, you can streamline the process by selecting a specific code cell, navigating to Runtime > Run after. This action will execute the selected cell and all subsequent cells automatically."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Reading model and expression data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UB3oPcTtMhDS",
        "outputId": "f8c5aa1e-c751-43ca-d308-cadaeba93ba9"
      },
      "outputs": [],
      "source": [
        "# Reading model with cobra\n",
        "\n",
        "begin_reading = time.time()\n",
        "\n",
        "is_xml = model_file_path.endswith(\".xml\")\n",
        "is_mat = model_file_path.endswith(\".mat\")\n",
        "try:\n",
        "  if is_xml:\n",
        "    model = cobra.io.read_sbml_model(model_file_path)\n",
        "    model_backup = cobra.io.read_sbml_model(model_file_path)\n",
        "    print(f' Model {model_file_path} is successfully read.')\n",
        "  elif is_mat:\n",
        "    model = cobra.io.load_matlab_model(model_file_path)\n",
        "    model_backup = cobra.io.load_matlab_model(model_file_path)\n",
        "    print(f' Model {model_file_path} is successfully read.')\n",
        "except:\n",
        "  print(f' Model {model_file_path} cannot be read. ')\n",
        "\n",
        "# Reading expression data\n",
        "is_xlsx = expression_file_path.endswith(\".xlsx\")\n",
        "is_csv = expression_file_path.endswith(\".csv\")\n",
        "try:\n",
        "  if is_xlsx:\n",
        "    expression_data = pd.read_excel(expression_file_path)\n",
        "    expression_data['Gene'] = expression_data['Gene'].astype(str)\n",
        "    print(f' Gene expression data {expression_file_path} is successfully read.')\n",
        "  elif is_csv:\n",
        "    expression_data = pd.read_csv(expression_file_path)\n",
        "    expression_data['Gene'] = expression_data['Gene'].astype(str)\n",
        "    print(f'Gene expression data {expression_file_path} is successfully read.')\n",
        "except:\n",
        "  print(f'Gene expression data {expression_file_path} cannot be read. ')\n",
        "\n",
        "end_reading = time.time()\n",
        "\n",
        "total_time_reading = end_reading - begin_reading\n",
        "print(f\"Runtime: {int(total_time_reading // 60)} min {int(total_time_reading % 60)} sec\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##  **Part 3 : GPRmapper** \n",
        "\n",
        "Returns a file of a reaction expression by calculating models gpr rule."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3Cvy6fx-83W",
        "outputId": "1aa0f510-507f-4e69-ab26-115043f15c89"
      },
      "outputs": [],
      "source": [
        "# Processing expression data with GPRmapper tool\n",
        "def parse_and_evaluate(expression):\n",
        "    while '(' in expression:\n",
        "        expression = re.sub(r'\\(([^()]+)\\)', lambda x: \"calculated_\" + str(calculate_rule(x.group(1))), expression)\n",
        "    return calculate_rule(expression)\n",
        "\n",
        "def calculate_rule(rule):\n",
        "    if 'and' in rule or 'or' in rule:\n",
        "        or_parts = rule.split('or')\n",
        "        or_results = []\n",
        "        for part in or_parts:\n",
        "            and_elements = part.split('and')\n",
        "            and_elements = [re.sub(r'[()]', '', element).strip() for element in and_elements]\n",
        "            and_averages = []\n",
        "            for element in and_elements:\n",
        "                if element.startswith('calculated_'):\n",
        "                    avg_sum = float(element[11:])\n",
        "                else:\n",
        "                    filtered_df = expression_data[expression_data['Gene'] == element]\n",
        "                    if not filtered_df.empty:\n",
        "                        avg_sum = filtered_df.drop(columns=['Gene']).mean(axis=1).mean()\n",
        "                    else:\n",
        "                        avg_sum = 0\n",
        "                and_averages.append(avg_sum)\n",
        "            if 'and' in part:\n",
        "                or_results.append(min(and_averages) if and_averages else 0)\n",
        "            else:\n",
        "                or_results.append(sum(and_averages) if and_averages else 0)\n",
        "        return sum(or_results)\n",
        "    else:\n",
        "        filtered_df = expression_data[expression_data['Gene'] == rule]\n",
        "        if not filtered_df.empty:\n",
        "            return filtered_df.drop(columns=['Gene']).mean(axis=1).mean()\n",
        "        return 0\n",
        "\n",
        "begin_gpr = time.time()\n",
        "\n",
        "# Extracting reaction rules\n",
        "reaction_rules = []\n",
        "for i, reaction in enumerate(model.reactions):\n",
        "  rule = reaction.gene_reaction_rule\n",
        "  reaction_rules.append(rule)\n",
        "GPR_file = [parse_and_evaluate(rule) for rule in reaction_rules]\n",
        "print('Reaction rules are extracted.')\n",
        "\n",
        "end_gpr = time.time()\n",
        "\n",
        "total_time_gpr = end_gpr - begin_gpr\n",
        "print(f\"Runtime: {int(total_time_gpr // 60)} min {int(total_time_gpr % 60)} sec\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Saving gpr data to as excel.\n",
        "GPR_file_df = pd.DataFrame(GPR_file)\n",
        "GPR_file_df.to_excel(\"GPRmapper_output.xlsx\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxKPek6JjpKX"
      },
      "source": [
        "# **Part 4: fE-flux Analysis**\n",
        "\n",
        "*   **Execution  :**  Run the specified code cell to start the fE-flux analysis.\n",
        "\n",
        "*   **Logging :** Upon execution, a log file named **\"fEflux_process_log.txt\"** will be generated and stored in the previously created data folder (refer to Part 1 for the folder details). This log file contains essential details of the analysis process.\n",
        "\n",
        "*  **Debugging (Optional) :** If you wish to enable debugging for more detailed process insights, please set the designated area to **\"True\"**.\n",
        "\n",
        "*  **Re-running Analysis  :** Should you need to conduct the Feasible E-flux analysis again, it is crucial to first re-execute the **\"Reading model and expression data\"** cell located in Part 2. This step is necessary to ensure the analysis uses the most current data. Be sure to back up the old log file if necessary.\n",
        "\n",
        "This structured approach is designed to streamline the Feasible E-flux analysis, ensuring both efficiency and accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FVA\n",
        "begin_fva = time.time()\n",
        "\n",
        "fva_result = flux_variability_analysis(model)\n",
        "print('FVA is completed')\n",
        "\n",
        "# Optimization\n",
        "fva_result['maximum'] = fva_result['maximum'].apply(lambda x: 0 if x < 0.00001 else x)\n",
        "fva_result['minimum'] = fva_result['minimum'].apply(lambda x: 0 if x < 0.00001 else x)\n",
        "fva_result.loc[fva_result['maximum'] < fva_result['minimum'], ['maximum', 'minimum']] = fva_result.loc[fva_result['maximum'] < fva_result['minimum'], ['minimum', 'maximum']].values\n",
        "\n",
        "max_fluxes = fva_result.maximum.to_list()\n",
        "min_fluxes = fva_result.minimum.to_list()\n",
        "print('FVA results are optimized')\n",
        "\n",
        "end_fva = time.time()\n",
        "\n",
        "total_time_fva = end_fva - begin_fva\n",
        "print(f\"Runtime: {int(total_time_fva // 60)} min {int(total_time_fva % 60)} sec\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Running fE-flux"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "WrytgLmPjxmi"
      },
      "outputs": [],
      "source": [
        "# Integrating expression data in your model with feasible Eflux method - fEflux tool\n",
        "begin_eflux = time.time()\n",
        "\n",
        "# Log file preperation\n",
        "\n",
        "debugging = False \n",
        "\n",
        "logger_name = \"fEflux_process_logger\"\n",
        "log_path = \"fEflux_process_log.txt\"\n",
        "\n",
        "if os.path.exists(log_path):\n",
        "    os.remove(log_path)\n",
        "\n",
        "logger = logging.getLogger(logger_name)\n",
        "logger.setLevel(logging.INFO)\n",
        "logger.propagate = debugging\n",
        "\n",
        "file_handler = logging.FileHandler(log_path)\n",
        "file_handler.setLevel(logging.INFO)\n",
        "\n",
        "log_format = '%(asctime)s - %(message)s'\n",
        "formatter = logging.Formatter(log_format)\n",
        "file_handler.setFormatter(formatter)\n",
        "\n",
        "logger.addHandler(file_handler)\n",
        "\n",
        "# Performing log2 normalization for GPRmapper output.\n",
        "normalized_GPR_file = [\n",
        "    0 if value is None or np.isnan(value) else np.log2(value) if value > 1 else value\n",
        "    for value in GPR_file\n",
        "    ]\n",
        "print('Reaction rules are normalized')\n",
        "\n",
        "# Initialize counters\n",
        "all_set = False\n",
        "process_count, negative_gpr, infeasible_in_lb, infeasible_in_ub, bounds_processed, nan_gpr, bounds_are_zero = 0, 0, 0, 0, 0, 0, 0\n",
        "\n",
        "print(f'''\n",
        "Reaction Number is {len(model.reactions)}\n",
        "Process is starting..\n",
        "      ''')\n",
        "\n",
        "# Ignore specific solver infeasibility warnings\n",
        "warnings.filterwarnings('ignore', category=UserWarning, message=\"Solver status is 'infeasible'.\")\n",
        "# Take  maximum  value\n",
        "max_Rxnexp = max(normalized_GPR_file)\n",
        "\n",
        "time.sleep(1.5)\n",
        "\n",
        "print(\"Trying to change all reaction bounds of model at once.\")\n",
        "\n",
        "# Backup Model used for creating all reactions applied with fEflux.\n",
        "for i, reaction in enumerate(model_backup.reactions):\n",
        "    if normalized_GPR_file[i] > 0 and pd.isna(normalized_GPR_file[i]) == False:\n",
        "        reaction.lower_bound = (normalized_GPR_file[i] / max_Rxnexp) * min_fluxes[i]\n",
        "        reaction.upper_bound = (normalized_GPR_file[i] / max_Rxnexp) * max_fluxes[i]\n",
        "all_set = model.optimize().status == \"feasible\"\n",
        "\n",
        "if not all_set:\n",
        "    print(\"Failed. E-flux optimization procedure has started.\")\n",
        "    for i, reaction in enumerate(model.reactions):\n",
        "        process_count += 1\n",
        "\n",
        "        if reaction.lower_bound != 0 or reaction.upper_bound != 0:\n",
        "\n",
        "            if normalized_GPR_file[i] < 0:\n",
        "                negative_gpr += 1\n",
        "                logger.info(f\"Reaction {i}      : Skipped. GPR value is negative.\")\n",
        "                continue\n",
        "\n",
        "            if normalized_GPR_file[i] >= 0 and pd.isna(normalized_GPR_file[i]) == False:\n",
        "                \n",
        "                try:\n",
        "                    backup_lb = reaction.lower_bound\n",
        "                    backup_ub = reaction.upper_bound\n",
        "                    \n",
        "                    reaction.lower_bound = (normalized_GPR_file[i] / max_Rxnexp) * min_fluxes[i]\n",
        "                    reaction.upper_bound = (normalized_GPR_file[i] / max_Rxnexp) * max_fluxes[i] \n",
        "\n",
        "                    solution = model.optimize()\n",
        "                    if solution.status == \"feasible\":\n",
        "                        bounds_processed += 1\n",
        "                        continue\n",
        "                \n",
        "                except:   \n",
        "                    reaction.lower_bound = backup_lb\n",
        "                    reaction.upper_bound = backup_ub\n",
        "                \n",
        "                # Solving LOWER bound\n",
        "                reaction.lower_bound = (normalized_GPR_file[i] / max_Rxnexp) * min_fluxes[i]\n",
        "\n",
        "                solution = model.optimize()\n",
        "                if solution.status == \"infeasible\":\n",
        "                    reaction.upper_bound = max_fluxes[i]\n",
        "                    reaction.lower_bound = min_fluxes[i]\n",
        "                    \n",
        "\n",
        "                    infeasible_in_lb += 1\n",
        "                    logger.info(f\"Reaction {i}      : Bounds are assigned as max-min values. Infeasible reaction caused while lower bound change.\")\n",
        "                    continue\n",
        "\n",
        "                # Solving UPPER bound\n",
        "                reaction.upper_bound = (normalized_GPR_file[i] / max_Rxnexp) * max_fluxes[i]\n",
        "\n",
        "                solution = model.optimize()\n",
        "                if solution.status == \"infeasible\":\n",
        "                    reaction.upper_bound = max_fluxes[i]\n",
        "\n",
        "                    infeasible_in_ub += 1\n",
        "                    logger.info(f\"Reaction {i}      : Upper bound is assigned as max value. Infeasible reaction caused while upper bound change.\")\n",
        "                    continue\n",
        "\n",
        "                bounds_processed += 1\n",
        "                continue\n",
        "\n",
        "            # If there is a NaN value\n",
        "            else:\n",
        "                nan_gpr += 1\n",
        "                logger.info(f\"Reaction {i}      : Skipped. GPR value is Nan.\")\n",
        "                continue\n",
        "\n",
        "        # If both values are 0\n",
        "        else:\n",
        "            bounds_are_zero += 1\n",
        "            logger.info(f\"Reaction {i}      : Skipped. Both lower and upper bounds are 0.\")\n",
        "            continue\n",
        "\n",
        "end_eflux = time.time()\n",
        "\n",
        "total_time_eflux = end_eflux - begin_eflux\n",
        "totol_runtime = total_time_eflux +  total_time_fva + total_time_gpr + total_time_reading\n",
        "\n",
        "if all_set:\n",
        "    print(\"Succesfull. The model is feasible with bound values of expression data. Process has completed.\")\n",
        "else:\n",
        "    print(f\"\"\"\n",
        "> E-flux optimization is completed.\n",
        "> Log file for details is saved as {log_path}\n",
        "\n",
        "                    ===   Result overview   ===\n",
        "Reactions Processed                         :      {process_count}\n",
        "Total Reactions in Model                    :      {len(model.reactions)}\n",
        "    (These values should match.)\n",
        "\n",
        "Bounds Processed                            :      {bounds_processed}\n",
        "    (Indicates the number of reaction bounds that could feasibly be altered.)\n",
        "\n",
        "Lower Bound Infeasible                      :      {infeasible_in_lb}\n",
        "Upper Bound Infeasible                      :      {infeasible_in_ub}\n",
        "    (These figures represent the number of reactions that became infeasible after changing bound. Bounds were adjusted to maximum and minimum values.)\n",
        "\n",
        "Negative GPR Associations                   :      {negative_gpr}\n",
        "Non-Numerical (NaN) GPR Associations        :      {nan_gpr}\n",
        "    (These scenarios indicate instances where the expression data could not be processed (which is not desired) and were therefore omitted.)\n",
        "\n",
        "Reactions with Bounds Already Set to Zero   :      {bounds_are_zero}\n",
        "\n",
        "Process has completed.\n",
        "\n",
        "Runtime: {int(total_time_eflux // 60)} min {int(total_time_eflux % 60)} sec\n",
        "\n",
        "Total Runtime:  {int(totol_runtime // 60)}  min {int(totol_runtime % 60)} sec\n",
        "        \"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Saving model as MATLAB\n",
        "if all_set:\n",
        "    save_matlab_model(model_backup ,\"feasible_model.mat\")\n",
        "else:\n",
        "    save_matlab_model(model_backup ,\"infeasible_model.mat\")\n",
        "    save_matlab_model(model ,\"feasible_model.mat\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
